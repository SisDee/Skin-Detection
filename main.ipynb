{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Assignment 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description of dataset and problem\n",
    "\n",
    "The dataset was adapted from [archive.ics.uci.edu](https://archive.ics.uci.edu/ml/datasets/Skin+Segmentation) and consist of $(B,G,R)$ colur scheme points that are labelled as human skin or not human skin. The dataset consist of $245\\ 057$ samples of which $50\\ 859$ are samples that represent human skin and $194\\ 198$ samples are not human skin. A datapoint from the dataset is of the following format $(B,G,R,C)$ where $B,G$ and $R$ are 8 bit integers ($[0,255]$) and $C$ represents the class in which the point belongs to , a value of $1$ indicates human skin while $2$ represents not human skin.With this dataset we want to implement classifiers for skin segmentation and evaluate their perfomance.The two models that will be implemented are logistic regression and naive bayes.\n",
    "\n",
    "## Preprocessing of data\n",
    "\n",
    "Before the data is used in any of the models it will be normalized and the class labels altered, the normalization is as follows\n",
    "$$x_i=\\frac{x_i-x_{min}}{x_{max}-x_{min}}$$\n",
    "The class labels will become $[1,2]\\to[0,1]$ .The dataset will the be split int three parts , one part to be used as training data which will be $60 \\%$ of the dataset , a second part to be used as validation data which will  $20\\%$ of the dataset and a testing set which will also $20\\%$ of the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading of dataset & sample points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Blue</th>\n",
       "      <th>Green</th>\n",
       "      <th>Red</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>74</td>\n",
       "      <td>85</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>73</td>\n",
       "      <td>84</td>\n",
       "      <td>122</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>72</td>\n",
       "      <td>83</td>\n",
       "      <td>121</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>81</td>\n",
       "      <td>119</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>70</td>\n",
       "      <td>81</td>\n",
       "      <td>119</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Blue  Green  Red  Class\n",
       "0    74     85  123      1\n",
       "1    73     84  122      1\n",
       "2    72     83  121      1\n",
       "3    70     81  119      1\n",
       "4    70     81  119      1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainingData=pd.read_csv('training_data.csv',names=['Blue','Green','Red','Class'])\n",
    "validationData=pd.read_csv('validation_data.csv',names=['Blue','Green','Red','Class'])\n",
    "testingData=pd.read_csv('testing_data.csv',names=['Blue','Green','Red','Class'])\n",
    "trainingData.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization & class reassignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Blue</th>\n",
       "      <th>Green</th>\n",
       "      <th>Red</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7222</th>\n",
       "      <td>0.454902</td>\n",
       "      <td>0.501961</td>\n",
       "      <td>0.729412</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Blue     Green       Red  Class\n",
       "7222  0.454902  0.501961  0.729412      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainingData[['Blue','Green','Red']]=trainingData[['Blue','Green','Red']].div(255)\n",
    "trainingData[['Class']]=trainingData[['Class']]-1\n",
    "validationData[['Blue','Green','Red']]=validationData[['Blue','Green','Red']].div(255)\n",
    "validationData[['Class']]=validationData[['Class']]-1\n",
    "testingData[['Blue','Green','Red']]=testingData[['Blue','Green','Red']].div(255)\n",
    "testingData[['Class']]=testingData[['Class']]-1\n",
    "trainingData.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### logistic regression\n",
    "Logistic regression in which the optimization method for determinining optimal values of $\\theta=(\\theta_0,\\theta_1,\\theta_2)$ is the minibatch gradient descent. Minibatch gradient descent is some hybrid between batch gradient descent and stochastic gradient descent.Instead of cycling through entire dataset first before perfoming an update we cycle through a minibatch thats significantly smaller than the dataset and update afterwards and unlike stochastic gradient descent we do not approximate gradient to a single point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5.56683359  4.65058547 -7.16665764]\n"
     ]
    }
   ],
   "source": [
    "def sigmoid(theta):\n",
    "    return lambda x:1/(1+np.exp(-np.dot(theta,x)))\n",
    "\n",
    "#minibatch gradient descent\n",
    "def mgd(epochs,batchSize,alpha):\n",
    "    data=[]\n",
    "    for index,row in trainingData.iterrows():\n",
    "        b,g,r,y=row['Blue'],row['Green'],row['Red'],row['Class']\n",
    "        data.append([[b,g,r],int(y)])\n",
    "    \n",
    "    theta=np.random.randn(3)    \n",
    "    for i in range(epochs):\n",
    "        np.random.shuffle(data)\n",
    "        miniBatches=[data[k:k+batchSize] for k in range(0,len(data),batchSize)]\n",
    "        for miniBatch in miniBatches:\n",
    "            h=sigmoid(theta)\n",
    "            temp=np.zeros(3)\n",
    "            prior=theta\n",
    "            for j in range(len(theta)):\n",
    "                gradients=[alpha*(h(x)-y)*x[j] for x,y in miniBatch]\n",
    "                temp[j]=(1/batchSize)*sum(gradients)\n",
    "            theta=theta-temp\n",
    "            eta=theta-prior\n",
    "            if np.sqrt(np.dot(eta,eta))<10**-5:\n",
    "                return theta\n",
    "    return theta\n",
    "def classify(h,x):\n",
    "    if h(x)<0.5:\n",
    "        return 0\n",
    "    return 1\n",
    "\n",
    "def accuracy(data,theta):\n",
    "    score=0\n",
    "    h=sigmoid(theta)\n",
    "    \n",
    "    for row in data:\n",
    "        if classify(h,row[0])==row[1]:\n",
    "            score=score+1\n",
    "    return 100*score/len(data)\n",
    "\n",
    "#testing how accurate model is by using it on a dataset            \n",
    "def fit(theta,training=False,test=False):\n",
    "    data=[]\n",
    "    if training:\n",
    "        for index,row in trainingData.iterrows():\n",
    "            b,g,r,y=row['Blue'],row['Green'],row['Red'],row['Class']\n",
    "            data.append([[b,g,r],int(y)])\n",
    "    elif test:\n",
    "        for index,row in testingData.iterrows():\n",
    "            b,g,r,y=row['Blue'],row['Green'],row['Red'],row['Class']\n",
    "            data.append([[b,g,r],int(y)])\n",
    "    return accuracy(data,theta)\n",
    "            \n",
    "theta=mgd(2,10,0.9)\n",
    "print(theta)\n",
    "\n",
    "# perfomance=fit(theta,training=True)\n",
    "# print(\"Training score\",perfomance)\n",
    "perfomance=fit(theta,test=True)\n",
    "print(\"Testing score\",perfomance,\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive bayes\n",
    "\n",
    "In implementing the naive bayes classifier we assume that all of the features follow the normal distribution with respect for a certain class.This allows us to generate a probability value for an a new unseen point.Since the normal distribution was used probability values of zero will not occur therefore there is no need for smoothing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian(mean,std):\n",
    "    return lambda x:(1/np.sqrt(2*np.pi*std**2))*np.exp(-1*((x-mean)**2)/(2*std**2))\n",
    "\n",
    "#returns the mean and stddev of feature with respect to a class\n",
    "def summary(name,group):\n",
    "    sample=trainingData[[name,'Class']]\n",
    "    sample=sample[sample['Class']==group]\n",
    "    mean=sample[[name]].mean()[0]\n",
    "    std=sample[[name]].std()[0]\n",
    "    \n",
    "    return mean,std\n",
    "#returns six normal distribution to be used in bayes rule\n",
    "def pdfs():\n",
    "    names=['Blue','Green','Red']\n",
    "    functions=[]\n",
    "    for j in range(2):\n",
    "        for name in names:\n",
    "            mean,std=summary(name,j)\n",
    "            p=gaussian(mean,std)\n",
    "            functions.append(p)\n",
    "            \n",
    "    return functions\n",
    "#returns a probability density function that takes in (b,g,r) and return probabili\n",
    "def naiveBayes():\n",
    "    #class probabilities\n",
    "    p=len(trainingData[trainingData['Class']==0])/len(trainingData)\n",
    "    q=1-p\n",
    "    #normal distributions\n",
    "    f=pdfs()\n",
    "    #probability density function which will use to classify\n",
    "    pds=lambda b,g,r:(p*f[0](b)*f[1](g)*f[2](r))/(p*f[0](b)*f[1](g)*f[2](r)+q*f[3](b)*f[4](g)*f[5](r))\n",
    "    \n",
    "    return pds\n",
    "\n",
    "def classify(h,x):\n",
    "    b,g,r=x\n",
    "    if h(b,g,r)<0.5:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "def accuracy(data):\n",
    "    score=0\n",
    "    h=naiveBayes()\n",
    "    \n",
    "    for row in data:\n",
    "        if classify(h,row[0])==row[1]:\n",
    "            score=score+1\n",
    "    return 100*score/len(data)\n",
    "\n",
    "def fit(training=False,test=False):\n",
    "    data=[]\n",
    "    if training:\n",
    "        for index,row in trainingData.iterrows():\n",
    "            b,g,r,y=row['Blue'],row['Green'],row['Red'],row['Class']\n",
    "            data.append([[b,g,r],int(y)])\n",
    "    elif test:\n",
    "        for index,row in testingData.iterrows():\n",
    "            b,g,r,y=row['Blue'],row['Green'],row['Red'],row['Class']\n",
    "            data.append([[b,g,r],int(y)])\n",
    "    return accuracy(data)\n",
    "\n",
    "\n",
    "perfomance=fit(test=True)\n",
    "print(\"Testing score\",perfomance,\"%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
